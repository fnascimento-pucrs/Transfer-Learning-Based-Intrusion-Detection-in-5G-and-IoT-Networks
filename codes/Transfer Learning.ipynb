{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Common Features\n",
    "Do Transfer Learning with common features between BoT-IoT Dataset and UNSW-NB15 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Set seaborn theme to the plots\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoT-IoT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BoT-IoT Dataset\n",
    "data = pd.read_csv('../datasets/BoT-IoT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='igmp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting dataset labels\n",
    "data_labels=data[['attack']]\n",
    "\n",
    "# Drop the invalid features and select interested data features\n",
    "data_features=data[['proto','saddr','sport','daddr','dport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "data_features = data_features.fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['saddr'] = data_features['saddr'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['daddr'] = data_features['daddr'].astype(int)\n",
    "data_features['dport'] = data_features['dport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['attack']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "input_shape = (24,1,1)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(444, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "filepath = '../models/tmp/BoT-IoT_CNN_Detection.hdf5' # define where the model is saved\n",
    "callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "            patience = 2 # Stop after 2 steps with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True)]# Only save model if it is the best\n",
    "\n",
    "# Train-test Split 75% TRAIN - 25% TEST\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_features, data_labels, train_size=0.75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure model training\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"model = load_model('../models/BoT-IoT_CNN_Detection_Best.hdf5')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "x = list(range(1, len(test_loss) + 1))\n",
    "plt.plot(x, test_loss, color = 'orange', label = 'Test loss')\n",
    "plt.plot(x, train_loss, label = 'Training loss')\n",
    "plt.legend()\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch', weight='bold', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "train_acc = history.history['accuracy']\n",
    "test_acc = history.history['val_accuracy']\n",
    "x = list(range(1, len(test_acc) + 1))\n",
    "plt.plot(x, test_acc, color = 'orange', label = 'Test accuracy')\n",
    "plt.plot(x, train_acc, label = 'Training accuracy')\n",
    "plt.legend()\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Epoch', weight='bold', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "# Confusion matrix\n",
    "y_class = np.argmax(predicted, axis = 1) \n",
    "y_test=y_test.to_numpy()\n",
    "y_check = np.argmax(y_test, axis = 1) \n",
    "\n",
    "cmatrix = confusion_matrix(y_check, y_class)\n",
    "\n",
    "cmatrix_df = pd.DataFrame(cmatrix, index = ['Attack', 'Normal'], columns = ['Attack', 'Normal'])\n",
    "plt.title('Confusion matrix of the test/predicted attacks in BoT-IoT', weight='bold', fontsize=13)\n",
    "plt.tick_params(length=0)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Predicted Attacks')\n",
    "sns.heatmap(cmatrix_df, annot=True, cmap=\"YlGnBu\", fmt=\"d\", cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F1-Score\n",
    "#plt.figure(figsize=(15,8))\n",
    "class_rep = classification_report(y_check, y_class, target_names=['Attack', 'Normal'], output_dict=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "plt.tick_params(length=0)\n",
    "sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :-3].T, cmap=\"YlGnBu\", square=True, cbar=False, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. UNSW-NB15-Train-Basic for training and UNSW-NB15-Test+ for validation\n",
    "## Loading UNSW-NB15 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15-Train-Basic\n",
    "data = pd.read_csv('../datasets/UNSW-NB15-Train-Basic.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "# Drop the invalid features and select interested data features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_train, y_train=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15-Test+\n",
    "data = pd.read_csv('../datasets/UNSW-NB15-Test+.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "#Extracting dataset features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Generate 2 new columns to fit with training\n",
    "auxCol=data_features['sbytes']\n",
    "auxCol=0\n",
    "data_features.insert(13, 'proto_igmp', auxCol, True)\n",
    "data_features.insert(21, 'state_PAR', auxCol, True)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_test, y_test=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model\n",
    "Loading pretrained model from BoT-IoT and freeze convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model of BoT-IoT Dataset\n",
    "pre_trained_model = load_model('../models/BoT-IoT_CNN_Detection_Best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all layers to non trainable\n",
    "pre_trained_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the last 3 layers to get only the convolutional base\n",
    "pre_trained_model.pop()\n",
    "pre_trained_model.pop()\n",
    "pre_trained_model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "Creating the new model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model building\n",
    "modelFE = models.Sequential()\n",
    "modelFE.add(pre_trained_model)\n",
    "\n",
    "modelFE.add(layers.Flatten())\n",
    "modelFE.add(Dense(448, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.4))\n",
    "modelFE.add(Dense(224, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.3))\n",
    "modelFE.add(Dense(112, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.3))\n",
    "modelFE.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "modelFE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "filepath = '../models/tmp/TransferLearning_Detection.hdf5' # define where the model is saved\n",
    "callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "            patience = 2 # Stop after 5 steps with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True)]# Only save model if it is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure model training\n",
    "modelFE.compile(optimizer=tf.keras.optimizers.Adam(2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = modelFE.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15,  batch_size=2048, callbacks=callbacks)\n",
    "history_1=history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Best model from Transfer Learning\n",
    "Load and validate the final transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transfer Learning model\n",
    "modelFE = load_model('../models/TransferLearning_Detection_Best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "results = modelFE.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted = modelFE.predict(x_test)\n",
    "\n",
    "# Confusion matrix\n",
    "y_class = np.argmax(predicted, axis = 1)\n",
    "y_test1=y_test\n",
    "y_test1=y_test1.to_numpy()\n",
    "y_check = np.argmax(y_test1, axis = 1) \n",
    "\n",
    "cmatrix = confusion_matrix(y_check, y_class)\n",
    "\n",
    "cmatrix_df = pd.DataFrame(cmatrix, index = ['Attack', 'Normal'], columns = ['Attack', 'Normal'])\n",
    "plt.title('Confusion matrix of the test/predicted attacks using TL', weight='bold', fontsize=14)\n",
    "plt.tick_params(length=0)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Predicted Attacks')\n",
    "sns.heatmap(cmatrix_df, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F1-Score\n",
    "class_rep = classification_report(y_check, y_class, target_names = ['Attack', 'Normal'], output_dict=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "plt.tick_params(length=0)\n",
    "sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :-3].T, square=True, cbar=True, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Attack Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted)\n",
    "df.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack']=data['label']\n",
    "df['category']=data['attack_cat']\n",
    "df['normal']=data_labels['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['pred_attack', 'pred_normal', 'attack', 'category', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=df\n",
    "df=pd.get_dummies(df)\n",
    "df=round(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis=df.loc[df['category_analysis'] == 1]\n",
    "analysis=analysis[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "analysis_pred=analysis[['pred_attack','pred_normal']]\n",
    "analysis_check=analysis[['attack','normal']]\n",
    "\n",
    "backdoor=df.loc[df['category_backdoor'] == 1]\n",
    "backdoor=backdoor[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "backdoor_pred=backdoor[['pred_attack','pred_normal']]\n",
    "backdoor_check=backdoor[['attack','normal']]\n",
    "\n",
    "fuzzers=df.loc[df['category_fuzzers'] == 1]\n",
    "fuzzers=fuzzers[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "fuzzers_pred=fuzzers[['pred_attack','pred_normal']]\n",
    "fuzzers_check=fuzzers[['attack','normal']]\n",
    "\n",
    "normal=df.loc[df['category_normal'] == 1]\n",
    "normal=normal[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "normal_pred=normal[['pred_attack','pred_normal']]\n",
    "normal_check=normal[['attack','normal']]\n",
    "\n",
    "shellcode=df.loc[df['category_shellcode'] == 1]\n",
    "shellcode=shellcode[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "shellcode_pred=shellcode[['pred_attack','pred_normal']]\n",
    "shellcode_check=shellcode[['attack','normal']]\n",
    "\n",
    "worms=df.loc[df['category_worms'] == 1]\n",
    "worms=worms[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "worms_pred=worms[['pred_attack','pred_normal']]\n",
    "worms_check=worms[['attack','normal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctly detected\n",
    "countdata=pd.DataFrame()\n",
    "normal_c = normal['pred_normal'] * normal['normal']\n",
    "analysis_c = analysis['pred_attack'] * analysis['attack']\n",
    "backdoor_c = backdoor['pred_attack'] * backdoor['attack']\n",
    "fuzzers_c = fuzzers['pred_attack'] * fuzzers['attack']\n",
    "shellcode_c = shellcode['pred_attack'] * shellcode['attack']\n",
    "worms_c = worms['pred_attack'] * worms['attack']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count 0 and 1\n",
    "normal_c0 = (normal_c == 0).sum()\n",
    "normal_c1 = len(normal) - normal_c0\n",
    "\n",
    "analysis_c0 = (analysis_c == 0).sum()\n",
    "analysis_c1 = len(analysis) - analysis_c0\n",
    "\n",
    "backdoor_c0 = (backdoor_c == 0).sum()\n",
    "backdoor_c1 = len(backdoor) - backdoor_c0\n",
    "\n",
    "fuzzers_c0 = (fuzzers_c == 0).sum()\n",
    "fuzzers_c1 = len(fuzzers) - fuzzers_c0\n",
    "\n",
    "shellcode_c0 = (shellcode_c == 0).sum()\n",
    "shellcode_c1 = len(shellcode) - shellcode_c0\n",
    "\n",
    "worms_c0 = (worms_c == 0).sum()\n",
    "worms_c1 = len(worms) - worms_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_0, normal_1 = normal_c0*100 / len(normal), normal_c1*100 / len(normal)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(normal_0, normal_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_0, analysis_1 = analysis_c0*100 / len(analysis), analysis_c1*100 / len(analysis)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(analysis_0, analysis_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_0, backdoor_1 = backdoor_c0*100 / len(backdoor), backdoor_c1*100 / len(backdoor)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(backdoor_0, backdoor_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzers_0, fuzzers_1 = fuzzers_c0*100 / len(fuzzers), fuzzers_c1*100 / len(fuzzers)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(fuzzers_0, fuzzers_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shellcode_0, shellcode_1 = shellcode_c0*100 / len(shellcode), shellcode_c1*100 / len(shellcode)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(shellcode_0, shellcode_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worms_0, worms_1 = worms_c0*100 / len(worms), worms_c1*100 / len(worms)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(worms_0, worms_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\"Traffic\":\n",
    "                   [\"Normal\", \"Analysis\", \"Backdoor\", \"Fuzzers\", \"Shellcode\", \"Worms\"],\n",
    "                   \"Detected %\": [normal_1, analysis_1, backdoor_1, fuzzers_1, shellcode_1, worms_1],\n",
    "                   \"No Detected %\": [normal_0, analysis_0, backdoor_0, fuzzers_0, shellcode_0, worms_0],\n",
    "                   \"Detected Samples\": [normal_c1, analysis_c1, backdoor_c1, fuzzers_c1, shellcode_c1, worms_c1],\n",
    "                   \"No Detected Samples\": [normal_c0, analysis_c0, backdoor_c0, fuzzers_c0, shellcode_c0, worms_c0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['category_pred'] = np.where(((df['attack'] == 1) & (df['pred_attack'] == 1)) | ((df['normal'] == 1) & (df['pred_normal'] == 1)), 'Detected', 'No Detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot=dff[['category', 'category_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting target label distribution\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(x=data_plot['category'], data=data_plot, hue=data_plot['category_pred'])\n",
    "plt.title('The detection of the attacks in Test+ dataset', weight='bold', fontsize='18')\n",
    "plt.xticks(weight='bold', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve = pd.read_csv('C../others/No_TransferLearning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve['Detected %'] = summary['Detected %'] - improve['Detected %']\n",
    "improve['Detected Samples'] = summary['Detected Samples'] - improve['Detected Samples']\n",
    "del improve['No Detected %']\n",
    "del improve['No Detected Samples']\n",
    "\n",
    "improve.rename(columns = {'Detected %':'Detection Improvement %', 'Detected Samples':'Detected Samples Improvement'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSW-NB15-Train-Basic for training and UNSW-NB15-Test for validation with NO TRANSFER LEARNING\n",
    "## Loading UNSW-NB15 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15-Train-Basic\n",
    "data = pd.read_csv('../datasets/UNSW-NB15-Train-Basic.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "# Drop the invalid features and select interested data features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_train, y_train=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15\n",
    "data = pd.read_csv('../datasets/UNSW-NB15-Test.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "#Extracting dataset features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].replace('-', -1)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_test, y_test=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "input_shape = (24,1,1)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(444, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "filepath = '../models/tmp/TransferLearning_Detection_Full_NOTL.hdf5' # define where the model is saved\n",
    "callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "            patience = 2 # Stop after 5 steps with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True)]# Only save model if it is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure model training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25,  batch_size=2048, callbacks=callbacks)\n",
    "history_1=history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transfer Learning model\n",
    "model = load_model('../models/UNSW-NB15_NON-TF.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "# Confusion matrix\n",
    "y_class = np.argmax(predicted, axis = 1)\n",
    "y_test1=y_test\n",
    "y_test1=y_test1.to_numpy()\n",
    "y_check = np.argmax(y_test1, axis = 1) \n",
    "\n",
    "cmatrix = confusion_matrix(y_check, y_class)\n",
    "\n",
    "cmatrix_df = pd.DataFrame(cmatrix, index = ['Attack', 'Normal'], columns = ['Attack', 'Normal'])\n",
    "plt.title('Confusion matrix of the test/predicted attacks ', weight='bold', fontsize=18)\n",
    "plt.tick_params(length=0)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Predicted Attacks')\n",
    "sns.heatmap(cmatrix_df, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F1-Score\n",
    "class_rep = classification_report(y_check, y_class, target_names = ['Attack', 'Normal'], output_dict=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "plt.tick_params(length=0)\n",
    "sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :-3].T, square=True, cbar=True, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Attack Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted)\n",
    "df.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack']=data['label']\n",
    "df['category']=data['attack_cat']\n",
    "df['normal']=data_labels['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['pred_attack', 'pred_normal', 'attack', 'category', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=df\n",
    "df=pd.get_dummies(df)\n",
    "df=round(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis=df.loc[df['category_analysis'] == 1]\n",
    "analysis=analysis[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "analysis_pred=analysis[['pred_attack','pred_normal']]\n",
    "analysis_check=analysis[['attack','normal']]\n",
    "\n",
    "backdoor=df.loc[df['category_backdoor'] == 1]\n",
    "backdoor=backdoor[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "backdoor_pred=backdoor[['pred_attack','pred_normal']]\n",
    "backdoor_check=backdoor[['attack','normal']]\n",
    "\n",
    "fuzzers=df.loc[df['category_fuzzers'] == 1]\n",
    "fuzzers=fuzzers[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "fuzzers_pred=fuzzers[['pred_attack','pred_normal']]\n",
    "fuzzers_check=fuzzers[['attack','normal']]\n",
    "\n",
    "normal=df.loc[df['category_normal'] == 1]\n",
    "normal=normal[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "normal_pred=normal[['pred_attack','pred_normal']]\n",
    "normal_check=normal[['attack','normal']]\n",
    "\n",
    "shellcode=df.loc[df['category_shellcode'] == 1]\n",
    "shellcode=shellcode[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "shellcode_pred=shellcode[['pred_attack','pred_normal']]\n",
    "shellcode_check=shellcode[['attack','normal']]\n",
    "\n",
    "worms=df.loc[df['category_worms'] == 1]\n",
    "worms=worms[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "worms_pred=worms[['pred_attack','pred_normal']]\n",
    "worms_check=worms[['attack','normal']]\n",
    "\n",
    "generic=df.loc[df['category_generic'] == 1]\n",
    "generic=generic[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "generic_pred=generic[['pred_attack','pred_normal']]\n",
    "generic_check=generic[['attack','normal']]\n",
    "\n",
    "exploits=df.loc[df['category_exploits'] == 1]\n",
    "exploits=exploits[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "exploits_pred=exploits[['pred_attack','pred_normal']]\n",
    "exploits_check=exploits[['attack','normal']]\n",
    "\n",
    "reconnaissance=df.loc[df['category_reconnaissance'] == 1]\n",
    "reconnaissance=reconnaissance[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "reconnaissance_pred=reconnaissance[['pred_attack','pred_normal']]\n",
    "reconnaissance_check=reconnaissance[['attack','normal']]\n",
    "\n",
    "dos=df.loc[df['category_dos'] == 1]\n",
    "dos=dos[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "dos_pred=dos[['pred_attack','pred_normal']]\n",
    "dos_check=dos[['attack','normal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctly detected\n",
    "countdata=pd.DataFrame()\n",
    "normal_c = normal['pred_normal'] * normal['normal']\n",
    "analysis_c = analysis['pred_attack'] * analysis['attack']\n",
    "backdoor_c = backdoor['pred_attack'] * backdoor['attack']\n",
    "fuzzers_c = fuzzers['pred_attack'] * fuzzers['attack']\n",
    "shellcode_c = shellcode['pred_attack'] * shellcode['attack']\n",
    "worms_c = worms['pred_attack'] * worms['attack']\n",
    "generic_c = generic['pred_attack'] * generic['attack']\n",
    "exploits_c = exploits['pred_attack'] * exploits['attack']\n",
    "reconnaissance_c = reconnaissance['pred_attack'] * reconnaissance['attack']\n",
    "dos_c = dos['pred_attack'] * dos['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count 0 and 1\n",
    "normal_c0 = (normal_c == 0).sum()\n",
    "normal_c1 = len(normal) - normal_c0\n",
    "\n",
    "analysis_c0 = (analysis_c == 0).sum()\n",
    "analysis_c1 = len(analysis) - analysis_c0\n",
    "\n",
    "backdoor_c0 = (backdoor_c == 0).sum()\n",
    "backdoor_c1 = len(backdoor) - backdoor_c0\n",
    "\n",
    "fuzzers_c0 = (fuzzers_c == 0).sum()\n",
    "fuzzers_c1 = len(fuzzers) - fuzzers_c0\n",
    "\n",
    "shellcode_c0 = (shellcode_c == 0).sum()\n",
    "shellcode_c1 = len(shellcode) - shellcode_c0\n",
    "\n",
    "worms_c0 = (worms_c == 0).sum()\n",
    "worms_c1 = len(worms) - worms_c0\n",
    "\n",
    "generic_c0 = (generic_c == 0).sum()\n",
    "generic_c1 = len(generic) - generic_c0\n",
    "\n",
    "exploits_c0 = (exploits_c == 0).sum()\n",
    "exploits_c1 = len(exploits) - exploits_c0\n",
    "\n",
    "reconnaissance_c0 = (reconnaissance_c == 0).sum()\n",
    "reconnaissance_c1 = len(reconnaissance) - reconnaissance_c0\n",
    "\n",
    "dos_c0 = (dos_c == 0).sum()\n",
    "dos_c1 = len(dos) - dos_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_0, normal_1 = normal_c0*100 / len(normal), normal_c1*100 / len(normal)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(normal_0, normal_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_0, analysis_1 = analysis_c0*100 / len(analysis), analysis_c1*100 / len(analysis)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(analysis_0, analysis_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_0, backdoor_1 = backdoor_c0*100 / len(backdoor), backdoor_c1*100 / len(backdoor)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(backdoor_0, backdoor_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzers_0, fuzzers_1 = fuzzers_c0*100 / len(fuzzers), fuzzers_c1*100 / len(fuzzers)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(fuzzers_0, fuzzers_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shellcode_0, shellcode_1 = shellcode_c0*100 / len(shellcode), shellcode_c1*100 / len(shellcode)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(shellcode_0, shellcode_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worms_0, worms_1 = worms_c0*100 / len(worms), worms_c1*100 / len(worms)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(worms_0, worms_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_0, generic_1 = generic_c0*100 / len(generic), generic_c1*100 / len(generic)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(generic_0, generic_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploits_0, exploits_1 = exploits_c0*100 / len(exploits), exploits_c1*100 / len(exploits)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(exploits_0, exploits_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconnaissance_0, reconnaissance_1 = reconnaissance_c0*100 / len(reconnaissance), reconnaissance_c1*100 / len(reconnaissance)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(reconnaissance_0, reconnaissance_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_0, dos_1 = dos_c0*100 / len(dos), dos_c1*100 / len(dos)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(dos_0, dos_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\"Traffic\":\n",
    "                   [\"Normal\", \"Analysis\", \"Backdoor\", \"Fuzzers\", \"Shellcode\", \"Worms\", \"Generic\", \"Exploits\", \"Reconnaissance\", \"DoS\"],\n",
    "                   \"Detected %\": [normal_1, analysis_1, backdoor_1, fuzzers_1, shellcode_1, worms_1, generic_1, exploits_1, reconnaissance_1, dos_1],\n",
    "                   \"No Detected %\": [normal_0, analysis_0, backdoor_0, fuzzers_0, shellcode_0, worms_0, generic_0, exploits_0, reconnaissance_0, dos_0],\n",
    "                   \"Detected Samples\": [normal_c1, analysis_c1, backdoor_c1, fuzzers_c1, shellcode_c1, worms_c1, generic_c1, exploits_c1, reconnaissance_c1, dos_c1],\n",
    "                   \"No Detected Samples\": [normal_c0, analysis_c0, backdoor_c0, fuzzers_c0, shellcode_c0, worms_c0, generic_c0, exploits_c0, reconnaissance_c0, dos_c0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['category_pred'] = np.where(((df['attack'] == 1) & (df['pred_attack'] == 1)) | ((df['normal'] == 1) & (df['pred_normal'] == 1)), 'Detected', 'No Detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot=dff[['category', 'category_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting target label distribution\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(x=data_plot['category'], data=data_plot, hue=data_plot['category_pred'])\n",
    "plt.title('The detection of the attacks in Test+ dataset', weight='bold', fontsize='18')\n",
    "plt.xticks(weight='bold', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('../others/No_TransferLearningFull.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSW-NB15-Train-Basic for training and UNSW-NB15 for validation using TRANSFER LEARNING\n",
    "## Loading UNSW-NB15 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15-Train-Basic\n",
    "data = pd.read_csv('../datasets/UNSW-NB15-Train-Basic.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "# Drop the invalid features and select interested data features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_train, y_train=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW-NB15-Test+\n",
    "data = pd.read_csv('C../datasets/UNSW-NB15-Test.csv', low_memory=False)\n",
    "\n",
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]\n",
    "\n",
    "# Extracting dataset labels\n",
    "data_labels=data[['label']]\n",
    "\n",
    "#Extracting dataset features\n",
    "data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dsport'] = data_features['dsport'].replace('-', -1)\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['label']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "x_test, y_test=data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model\n",
    "Loading pretrained model from BoT-IoT and freeze convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model of BoT-IoT Dataset\n",
    "pre_trained_model = load_model('../models/BoT-IoT_CNN_Detection_Best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all layers to non trainable\n",
    "pre_trained_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the last 3 layers to get only the convolutional base\n",
    "pre_trained_model.pop()\n",
    "pre_trained_model.pop()\n",
    "pre_trained_model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "Creating the new model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model building\n",
    "modelFE = models.Sequential()\n",
    "modelFE.add(pre_trained_model)\n",
    "\n",
    "modelFE.add(layers.Flatten())\n",
    "modelFE.add(Dense(448, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.4))\n",
    "modelFE.add(Dense(224, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.3))\n",
    "modelFE.add(Dense(112, activation='relu'))\n",
    "modelFE.add(layers.Dropout(0.3))\n",
    "modelFE.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "modelFE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "filepath = '../models/tmp/TransferLearning_Detection_Full.hdf5' # define where the model is saved\n",
    "callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "            patience = 2 # Stop after 5 steps with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True)]# Only save model if it is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure model training\n",
    "epochs=25\n",
    "modelFE.compile(optimizer=tf.keras.optimizers.Adam(2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = modelFE.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs,  batch_size=2048, callbacks=callbacks)\n",
    "history_1=history\n",
    "e=epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Best model from Transfer Learning\n",
    "Load and validate the final transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transfer Learning model\n",
    "modelFE = load_model('../datasets/TransferLearning_Detection_Best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "results = modelFE.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted = modelFE.predict(x_test)\n",
    "\n",
    "# Confusion matrix\n",
    "y_class = np.argmax(predicted, axis = 1)\n",
    "y_test1=y_test\n",
    "y_test1=y_test1.to_numpy()\n",
    "y_check = np.argmax(y_test1, axis = 1) \n",
    "\n",
    "cmatrix = confusion_matrix(y_check, y_class)\n",
    "\n",
    "cmatrix_df = pd.DataFrame(cmatrix, index = ['Attack', 'Normal'], columns = ['Attack', 'Normal'])\n",
    "plt.title('Confusion matrix of the test/predicted attacks ', weight='bold', fontsize=18)\n",
    "plt.tick_params(length=0)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Predicted Attacks')\n",
    "sns.heatmap(cmatrix_df, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F1-Score\n",
    "class_rep = classification_report(y_check, y_class, target_names = ['Attack', 'Normal'], output_dict=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "plt.tick_params(length=0)\n",
    "sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :-3].T, square=True, cbar=True, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Attack Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted)\n",
    "df.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack']=data['label']\n",
    "df['category']=data['attack_cat']\n",
    "df['normal']=data_labels['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['pred_attack', 'pred_normal', 'attack', 'category', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=df\n",
    "df=pd.get_dummies(df)\n",
    "df=round(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis=df.loc[df['category_analysis'] == 1]\n",
    "analysis=analysis[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "analysis_pred=analysis[['pred_attack','pred_normal']]\n",
    "analysis_check=analysis[['attack','normal']]\n",
    "\n",
    "backdoor=df.loc[df['category_backdoor'] == 1]\n",
    "backdoor=backdoor[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "backdoor_pred=backdoor[['pred_attack','pred_normal']]\n",
    "backdoor_check=backdoor[['attack','normal']]\n",
    "\n",
    "fuzzers=df.loc[df['category_fuzzers'] == 1]\n",
    "fuzzers=fuzzers[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "fuzzers_pred=fuzzers[['pred_attack','pred_normal']]\n",
    "fuzzers_check=fuzzers[['attack','normal']]\n",
    "\n",
    "normal=df.loc[df['category_normal'] == 1]\n",
    "normal=normal[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "normal_pred=normal[['pred_attack','pred_normal']]\n",
    "normal_check=normal[['attack','normal']]\n",
    "\n",
    "shellcode=df.loc[df['category_shellcode'] == 1]\n",
    "shellcode=shellcode[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "shellcode_pred=shellcode[['pred_attack','pred_normal']]\n",
    "shellcode_check=shellcode[['attack','normal']]\n",
    "\n",
    "worms=df.loc[df['category_worms'] == 1]\n",
    "worms=worms[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "worms_pred=worms[['pred_attack','pred_normal']]\n",
    "worms_check=worms[['attack','normal']]\n",
    "\n",
    "generic=df.loc[df['category_generic'] == 1]\n",
    "generic=generic[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "generic_pred=generic[['pred_attack','pred_normal']]\n",
    "generic_check=generic[['attack','normal']]\n",
    "\n",
    "exploits=df.loc[df['category_exploits'] == 1]\n",
    "exploits=exploits[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "exploits_pred=exploits[['pred_attack','pred_normal']]\n",
    "exploits_check=exploits[['attack','normal']]\n",
    "\n",
    "reconnaissance=df.loc[df['category_reconnaissance'] == 1]\n",
    "reconnaissance=reconnaissance[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "reconnaissance_pred=reconnaissance[['pred_attack','pred_normal']]\n",
    "reconnaissance_check=reconnaissance[['attack','normal']]\n",
    "\n",
    "dos=df.loc[df['category_dos'] == 1]\n",
    "dos=dos[['pred_attack', 'pred_normal', 'attack', 'normal']]\n",
    "dos_pred=dos[['pred_attack','pred_normal']]\n",
    "dos_check=dos[['attack','normal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctly detected\n",
    "countdata=pd.DataFrame()\n",
    "normal_c = normal['pred_normal'] * normal['normal']\n",
    "analysis_c = analysis['pred_attack'] * analysis['attack']\n",
    "backdoor_c = backdoor['pred_attack'] * backdoor['attack']\n",
    "fuzzers_c = fuzzers['pred_attack'] * fuzzers['attack']\n",
    "shellcode_c = shellcode['pred_attack'] * shellcode['attack']\n",
    "worms_c = worms['pred_attack'] * worms['attack']\n",
    "generic_c = generic['pred_attack'] * generic['attack']\n",
    "exploits_c = exploits['pred_attack'] * exploits['attack']\n",
    "reconnaissance_c = reconnaissance['pred_attack'] * reconnaissance['attack']\n",
    "dos_c = dos['pred_attack'] * dos['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count 0 and 1\n",
    "normal_c0 = (normal_c == 0).sum()\n",
    "normal_c1 = len(normal) - normal_c0\n",
    "\n",
    "analysis_c0 = (analysis_c == 0).sum()\n",
    "analysis_c1 = len(analysis) - analysis_c0\n",
    "\n",
    "backdoor_c0 = (backdoor_c == 0).sum()\n",
    "backdoor_c1 = len(backdoor) - backdoor_c0\n",
    "\n",
    "fuzzers_c0 = (fuzzers_c == 0).sum()\n",
    "fuzzers_c1 = len(fuzzers) - fuzzers_c0\n",
    "\n",
    "shellcode_c0 = (shellcode_c == 0).sum()\n",
    "shellcode_c1 = len(shellcode) - shellcode_c0\n",
    "\n",
    "worms_c0 = (worms_c == 0).sum()\n",
    "worms_c1 = len(worms) - worms_c0\n",
    "\n",
    "generic_c0 = (generic_c == 0).sum()\n",
    "generic_c1 = len(generic) - generic_c0\n",
    "\n",
    "exploits_c0 = (exploits_c == 0).sum()\n",
    "exploits_c1 = len(exploits) - exploits_c0\n",
    "\n",
    "reconnaissance_c0 = (reconnaissance_c == 0).sum()\n",
    "reconnaissance_c1 = len(reconnaissance) - reconnaissance_c0\n",
    "\n",
    "dos_c0 = (dos_c == 0).sum()\n",
    "dos_c1 = len(dos) - dos_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_0, normal_1 = normal_c0*100 / len(normal), normal_c1*100 / len(normal)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(normal_0, normal_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_0, analysis_1 = analysis_c0*100 / len(analysis), analysis_c1*100 / len(analysis)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(analysis_0, analysis_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_0, backdoor_1 = backdoor_c0*100 / len(backdoor), backdoor_c1*100 / len(backdoor)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(backdoor_0, backdoor_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzers_0, fuzzers_1 = fuzzers_c0*100 / len(fuzzers), fuzzers_c1*100 / len(fuzzers)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(fuzzers_0, fuzzers_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shellcode_0, shellcode_1 = shellcode_c0*100 / len(shellcode), shellcode_c1*100 / len(shellcode)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(shellcode_0, shellcode_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worms_0, worms_1 = worms_c0*100 / len(worms), worms_c1*100 / len(worms)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(worms_0, worms_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_0, generic_1 = generic_c0*100 / len(generic), generic_c1*100 / len(generic)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(generic_0, generic_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploits_0, exploits_1 = exploits_c0*100 / len(exploits), exploits_c1*100 / len(exploits)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(exploits_0, exploits_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconnaissance_0, reconnaissance_1 = reconnaissance_c0*100 / len(reconnaissance), reconnaissance_c1*100 / len(reconnaissance)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(reconnaissance_0, reconnaissance_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_0, dos_1 = dos_c0*100 / len(dos), dos_c1*100 / len(dos)\n",
    "print(\"There are {:.2f} % of NO detected and {:.2f} % of detected samples\".format(dos_0, dos_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\"Traffic\":\n",
    "                   [\"Normal\", \"Analysis\", \"Backdoor\", \"Fuzzers\", \"Shellcode\", \"Worms\", \"Generic\", \"Exploits\", \"Reconnaissance\", \"DoS\"],\n",
    "                   \"Detected %\": [normal_1, analysis_1, backdoor_1, fuzzers_1, shellcode_1, worms_1, generic_1, exploits_1, reconnaissance_1, dos_1],\n",
    "                   \"No Detected %\": [normal_0, analysis_0, backdoor_0, fuzzers_0, shellcode_0, worms_0, generic_0, exploits_0, reconnaissance_0, dos_0],\n",
    "                   \"Detected Samples\": [normal_c1, analysis_c1, backdoor_c1, fuzzers_c1, shellcode_c1, worms_c1, generic_c1, exploits_c1, reconnaissance_c1, dos_c1],\n",
    "                   \"No Detected Samples\": [normal_c0, analysis_c0, backdoor_c0, fuzzers_c0, shellcode_c0, worms_c0, generic_c0, exploits_c0, reconnaissance_c0, dos_c0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['category_pred'] = np.where(((df['attack'] == 1) & (df['pred_attack'] == 1)) | ((df['normal'] == 1) & (df['pred_normal'] == 1)), 'Detected', 'No Detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot=dff[['category', 'category_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting target label distribution\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(x=data_plot['category'], data=data_plot, hue=data_plot['category_pred'])\n",
    "plt.title('The detection of the attacks in Test+ dataset', weight='bold', fontsize='18')\n",
    "plt.xticks(weight='bold', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve = pd.read_csv('../others/No_TransferLearningFull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve['Detected %'] = summary['Detected %'] - improve['Detected %']\n",
    "improve['Detected Samples'] = summary['Detected Samples'] - improve['Detected Samples']\n",
    "del improve['No Detected %']\n",
    "del improve['No Detected Samples']\n",
    "\n",
    "improve.rename(columns = {'Detected %':'Detection Improvement %', 'Detected Samples':'Detected Samples Improvement'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f888873021ff2b56432b2ed856f78e908258ebea59af0d70cb1358e281cf934"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
