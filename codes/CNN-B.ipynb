{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoT-IoT Model Generation | CNN-B\n",
    "Training and generation of the CNN-B model with BoT-IoT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Set seaborn theme to the plots\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoT-IoT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BoT-IoT Dataset\n",
    "data = pd.read_csv('../datasets/BoT-IoT.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'proto' and 'state' values that I want\n",
    "data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='igmp'), :]\n",
    "data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] =='PAR'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting dataset labels\n",
    "data_labels=data[['attack']]\n",
    "\n",
    "# Select interested data features\n",
    "data_features=data[['proto','saddr','sport','daddr','dport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "# Filling NaN values with -1\n",
    "data_features = data_features.fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "# Preprocess IP and ports features\n",
    "# IP Source Address\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['saddr'] = data_features['saddr'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# IP Destination Address\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: x.split(\".\")[-1])\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: x.split(\":\")[-1])\n",
    "data_features['daddr'] = data_features['daddr'].apply(lambda x: int(x, 16))\n",
    "\n",
    "# Ports\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "# Convert all ports with 0 decimal, and HEX to DEC\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "data_features['dport'] = data_features['dport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "# Convert field to int format\n",
    "data_features['saddr'] = data_features['saddr'].astype(int)\n",
    "data_features['sport'] = data_features['sport'].astype(int)\n",
    "data_features['daddr'] = data_features['daddr'].astype(int)\n",
    "data_features['dport'] = data_features['dport'].astype(int)\n",
    "\n",
    "# Convert some fields to logarithmic\n",
    "log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "for col in log1p_col:\n",
    "    data_features[col] = data_features[col].apply(np.log1p)\n",
    "    \n",
    "# Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "normal=data_labels['attack']\n",
    "normal=normal.replace(1,2)\n",
    "normal=normal.replace(0,1)\n",
    "normal=normal.replace(2,0)\n",
    "\n",
    "# Insert the new column in data labels\n",
    "data_labels.insert(1, 'normal', normal)\n",
    "data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "# Transform to One hot encoding - FEATURES\n",
    "data_features=pd.get_dummies(data_features)\n",
    "\n",
    "# Normalize all data features\n",
    "data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "#Add dimension to data features\n",
    "data_features = np.expand_dims(data_features, axis=2)\n",
    "data_features = np.expand_dims(data_features, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-B model building and definition\n",
    "input_shape = (24,1,1)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(444, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "filepath = '../models/tmp/BoT-IoT_CNN_Detection.hdf5' # define where the model is saved\n",
    "callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "            patience = 2 # Stop after 2 steps with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True)]# Only save model if it is the best\n",
    "\n",
    "# Train-test Split 75% TRAIN - 25% TEST\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_features, data_labels, train_size=0.75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure model training\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('../models/BoT-IoT_CNN_Detection_Best.hdf5')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "x = list(range(1, len(test_loss) + 1))\n",
    "plt.plot(x, test_loss, color = 'orange', label = 'Test loss')\n",
    "plt.plot(x, train_loss, label = 'Training loss')\n",
    "plt.legend()\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch', weight='bold', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "train_acc = history.history['accuracy']\n",
    "test_acc = history.history['val_accuracy']\n",
    "x = list(range(1, len(test_acc) + 1))\n",
    "plt.plot(x, test_acc, color = 'orange', label = 'Test accuracy')\n",
    "plt.plot(x, train_acc, label = 'Training accuracy')\n",
    "plt.legend()\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Epoch', weight='bold', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "# Confusion matrix\n",
    "y_class = np.argmax(predicted, axis = 1) \n",
    "y_test=y_test.to_numpy()\n",
    "y_check = np.argmax(y_test, axis = 1) \n",
    "\n",
    "cmatrix = confusion_matrix(y_check, y_class)\n",
    "\n",
    "# Plotting Confusion Matrix\n",
    "cmatrix_df = pd.DataFrame(cmatrix, index = ['Attack', 'Normal'], columns = ['Attack', 'Normal'])\n",
    "plt.title('Confusion matrix of the test/predicted attacks in BoT-IoT CNN-B', weight='bold', fontsize=13)\n",
    "plt.tick_params(length=0)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Predicted Attacks')\n",
    "sns.heatmap(cmatrix_df, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F1-Score\n",
    "class_rep = classification_report(y_check, y_class, target_names=['Attack', 'Normal'], output_dict=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "plt.tick_params(length=0)\n",
    "sns.heatmap(pd.DataFrame(class_rep).iloc[:-1, :-3].T, cmap=\"YlGnBu\", square=True, cbar=False, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rep"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f888873021ff2b56432b2ed856f78e908258ebea59af0d70cb1358e281cf934"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
